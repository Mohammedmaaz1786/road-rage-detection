{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“‚ 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv3D, Flatten, MaxPooling3D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¥ 2. Convert Videos to .npy Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Convert videos to numpy format for faster processing\n",
    "def convert_videos_to_npy(input_path, output_path):\n",
    "    class_counters = {\"Fight\": 1, \"NonFight\": 1}\n",
    "    \n",
    "    for class_name in os.listdir(input_path):\n",
    "        class_dir = os.path.join(input_path, class_name)\n",
    "        class_output_dir = os.path.join(output_path, class_name)\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.isdir(class_dir):\n",
    "            for video_name in os.listdir(class_dir):\n",
    "                video_path = os.path.join(class_dir, video_name)\n",
    "                if video_name.endswith(('.mp4', '.avi', '.mkv')):  \n",
    "                    cap = cv2.VideoCapture(video_path)\n",
    "                    frames = []\n",
    "\n",
    "                    while True:\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret:\n",
    "                            break\n",
    "                        frame = cv2.resize(frame, (150, 150))  \n",
    "                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  \n",
    "                        frames.append(frame)\n",
    "\n",
    "                    cap.release()\n",
    "                    frames_array = np.array(frames, dtype=np.uint8)\n",
    "\n",
    "                    file_prefix = \"F\" if class_name == \"Fight\" else \"NF\"\n",
    "                    output_file = os.path.join(class_output_dir, f\"{file_prefix}_{class_counters[class_name]}.npy\")\n",
    "                    np.save(output_file, frames_array)\n",
    "                    print(f\"Converted and saved: {output_file}\")\n",
    "\n",
    "                    class_counters[class_name] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“¦ 3. Define the Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Data Generator to Load Preprocessed `.npy` Files\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data_folder, batch_size=32, dim=(30, 150, 150), n_channels=3, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.data_folder = data_folder\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label in ['Fight', 'NonFight']:\n",
    "            folder = os.path.join(data_folder, label)\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith('.npy'):\n",
    "                    self.files.append(os.path.join(folder, file))\n",
    "                    self.labels.append(1 if label == \"Fight\" else 0)\n",
    "\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty(self.batch_size, dtype=int)\n",
    "\n",
    "        for i, idx in enumerate(indexes):\n",
    "            X[i,] = np.load(self.files[idx]) / 255.0\n",
    "            y[i] = self.labels[idx]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“Œ 4. Define the 3D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Define the 3D CNN Model Architecture\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    \n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    \n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Train the Model\n",
    "dataset_folder = \"Dataset\"\n",
    "output_folder = \"Numpy_Videos\"\n",
    "\n",
    "CONVERT_VIDEOS = True  # Set to True if you need to convert videos\n",
    "\n",
    "if CONVERT_VIDEOS:\n",
    "    convert_videos_to_npy(dataset_folder, output_folder)\n",
    "\n",
    "print(\"Creating data generators...\")\n",
    "train_generator = DataGenerator(output_folder, batch_size=16)\n",
    "validation_generator = DataGenerator(output_folder, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "input_shape = (30, 150, 150, 3)\n",
    "model = create_model(input_shape)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=20,\n",
    "                    callbacks=[early_stopping, lr_scheduler])\n",
    "print(\"Model training process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¾ 6. Save the Violence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('violence_detection_model.h5')\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“Š 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Evaluate Model Performance\n",
    "print(\"Evaluating the model...\")\n",
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# ðŸ“Œ Generate Classification Report\n",
    "y_pred = model.predict(validation_generator)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "y_true = np.concatenate([label for _, label in validation_generator])\n",
    "y_true = y_true[:len(y_pred_classes)]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“ˆ 8. Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Plot Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NonFight', 'Fight'], yticklabels=['NonFight', 'Fight'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
